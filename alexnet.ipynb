{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Training a deep Convolutional Neural Network:**\n",
        "In this notebook, we will create an implementation of the AlexNet architecture and use it to classify images from the CIFAR10 dataset. We will train the network using two different optimization methods on a subset of the training data.\n",
        "\n",
        "**Q1:** \n",
        "\n",
        "We will use stochastic gradient descent (SGD) with a learning rate of $0.005$ to train the network on $10%$ of the training data.\n",
        "Then, we will use the Adam optimizer with a learning rate of $0.00005$ to train the network on the same $10%$ of the training data.\n",
        "\n"
      ],
      "metadata": {
        "id": "PBOtv7dyyQB-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILepV50L1MPW",
        "outputId": "ad2c6a88-1d23-40bc-e4c8-ef972f55db7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_valid_loader(data_dir,\n",
        "                           batch_size,\n",
        "                           augment,\n",
        "                           random_seed,\n",
        "                           valid_size=0.1,\n",
        "                           shuffle=True):\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010],\n",
        "    )\n",
        "\n",
        "    # define transforms\n",
        "    valid_transform = transforms.Compose([\n",
        "            transforms.Resize((227,227)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "    ])\n",
        "    if augment:\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "    else:\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.Resize((227,227)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "    # load the dataset\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=train_transform,\n",
        "    )\n",
        "\n",
        "    valid_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=valid_transform,\n",
        "    )\n",
        "\n",
        "    num_train = len(train_dataset)\n",
        "\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_idx = train_idx[: int(np.floor(len(train_idx) * 0.1))]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        " \n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "    return (train_loader, valid_loader)\n",
        "\n",
        "\n",
        "def get_test_loader(data_dir,\n",
        "                    batch_size,\n",
        "                    shuffle=True):\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225],\n",
        "    )\n",
        "\n",
        "    # define transform\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((227,227)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "\n",
        "    dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=False,\n",
        "        download=True, transform=transform,\n",
        "    )\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle\n",
        "    )\n",
        "\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "# CIFAR10 dataset \n",
        "train_loader, valid_loader = get_train_valid_loader(data_dir = './data', batch_size = 64,\n",
        "                       augment = False, random_seed = 1)\n",
        "\n",
        "test_loader = get_test_loader(data_dir = './data',\n",
        "                              batch_size = 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW8XBjhSNFfl",
        "outputId": "58810fcf-ab8b-4d3f-c8c4-900b39ad8643"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 47595602.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(9216, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "4Vd7u0CvNl-Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Q1:**\n",
        "The network will be trained using the SGD optimizer on the training data with a learning rate of $0.005$, and the output of the section below will print the Loss of each Epoch and Accuracy of the network on the $5000$ validation images of each epoch."
      ],
      "metadata": {
        "id": "t8qEu4Ua5PsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "learning_rate = 0.005\n",
        "\n",
        "model = AlexNet(num_classes).to(device)\n",
        "\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n"
      ],
      "metadata": {
        "id": "aiufRii0Nu8e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "total_step = len(train_loader)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, running_loss / len(train_loader)))\n",
        "            \n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "    \n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bofDnIfN5FI",
        "outputId": "1f7a9cc4-0c97-4520-937d-4fe7f1864e98"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [71/71], Loss: 2.1869\n",
            "Accuracy of the network on the 5000 validation images: 25.34 %\n",
            "Epoch [2/10], Step [71/71], Loss: 1.8636\n",
            "Accuracy of the network on the 5000 validation images: 29.64 %\n",
            "Epoch [3/10], Step [71/71], Loss: 1.6622\n",
            "Accuracy of the network on the 5000 validation images: 35.84 %\n",
            "Epoch [4/10], Step [71/71], Loss: 1.5509\n",
            "Accuracy of the network on the 5000 validation images: 39.3 %\n",
            "Epoch [5/10], Step [71/71], Loss: 1.4531\n",
            "Accuracy of the network on the 5000 validation images: 39.84 %\n",
            "Epoch [6/10], Step [71/71], Loss: 1.3914\n",
            "Accuracy of the network on the 5000 validation images: 39.58 %\n",
            "Epoch [7/10], Step [71/71], Loss: 1.3356\n",
            "Accuracy of the network on the 5000 validation images: 41.9 %\n",
            "Epoch [8/10], Step [71/71], Loss: 1.2625\n",
            "Accuracy of the network on the 5000 validation images: 45.22 %\n",
            "Epoch [9/10], Step [71/71], Loss: 1.2145\n",
            "Accuracy of the network on the 5000 validation images: 43.3 %\n",
            "Epoch [10/10], Step [71/71], Loss: 1.1383\n",
            "Accuracy of the network on the 5000 validation images: 48.7 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWePrDWfGuGv",
        "outputId": "bbd79097-f2de-4699-8601-2392e69a67db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 49.41 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The network will be trained using the Adam optimizer on the training data with a learning rate of $0.00005$, and the output of the section below will print the Loss of each Epoch and Accuracy of the network on the $5000$ validation images of each epoch."
      ],
      "metadata": {
        "id": "s3ExS2X15hhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.00005\n",
        "\n",
        "\n",
        "model = AlexNet(num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n"
      ],
      "metadata": {
        "id": "9AYqsdGLwbYQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "total_step = len(train_loader)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, running_loss / len(train_loader)))\n",
        "            \n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "    \n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu5R_qJowdm4",
        "outputId": "411ee780-d723-4823-990a-21d8d3745c2a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [71/71], Loss: 1.8515\n",
            "Accuracy of the network on the 5000 validation images: 39.3 %\n",
            "Epoch [2/10], Step [71/71], Loss: 1.4774\n",
            "Accuracy of the network on the 5000 validation images: 43.24 %\n",
            "Epoch [3/10], Step [71/71], Loss: 1.3239\n",
            "Accuracy of the network on the 5000 validation images: 49.3 %\n",
            "Epoch [4/10], Step [71/71], Loss: 1.1852\n",
            "Accuracy of the network on the 5000 validation images: 51.4 %\n",
            "Epoch [5/10], Step [71/71], Loss: 1.0820\n",
            "Accuracy of the network on the 5000 validation images: 54.82 %\n",
            "Epoch [6/10], Step [71/71], Loss: 0.9717\n",
            "Accuracy of the network on the 5000 validation images: 56.08 %\n",
            "Epoch [7/10], Step [71/71], Loss: 0.8601\n",
            "Accuracy of the network on the 5000 validation images: 57.02 %\n",
            "Epoch [8/10], Step [71/71], Loss: 0.8062\n",
            "Accuracy of the network on the 5000 validation images: 60.98 %\n",
            "Epoch [9/10], Step [71/71], Loss: 0.7059\n",
            "Accuracy of the network on the 5000 validation images: 60.62 %\n",
            "Epoch [10/10], Step [71/71], Loss: 0.6086\n",
            "Accuracy of the network on the 5000 validation images: 61.98 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq-z2io4Gv9F",
        "outputId": "b1a59801-9f2a-4258-85d1-c59a7ec519d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 62.49 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nLdqk51v7Ild"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Q2:**\n",
        "The network will be trained using the Adam optimizer on the training data with a learning rate of $0.005$, and the output of the section below will print the Loss of each Epoch and Accuracy of the network on the $5000$ validation images of each epoch."
      ],
      "metadata": {
        "id": "ljd_FbXf5uom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.005\n",
        "\n",
        "model = AlexNet(num_classes).to(device)\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n"
      ],
      "metadata": {
        "id": "_8b9IgS6x3b_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "total_step = len(train_loader)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, running_loss / len(train_loader)))\n",
        "            \n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "    \n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy7Gpw96x7tL",
        "outputId": "5e7ed0be-5a41-46dd-c912-8007294ce1eb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [71/71], Loss: 19.3668\n",
            "Accuracy of the network on the 5000 validation images: 13.18 %\n",
            "Epoch [2/10], Step [71/71], Loss: 2.4899\n",
            "Accuracy of the network on the 5000 validation images: 14.44 %\n",
            "Epoch [3/10], Step [71/71], Loss: 2.3805\n",
            "Accuracy of the network on the 5000 validation images: 15.18 %\n",
            "Epoch [4/10], Step [71/71], Loss: 2.2670\n",
            "Accuracy of the network on the 5000 validation images: 14.34 %\n",
            "Epoch [5/10], Step [71/71], Loss: 2.2545\n",
            "Accuracy of the network on the 5000 validation images: 14.1 %\n",
            "Epoch [6/10], Step [71/71], Loss: 2.2376\n",
            "Accuracy of the network on the 5000 validation images: 14.66 %\n",
            "Epoch [7/10], Step [71/71], Loss: 2.1805\n",
            "Accuracy of the network on the 5000 validation images: 15.12 %\n",
            "Epoch [8/10], Step [71/71], Loss: 2.1845\n",
            "Accuracy of the network on the 5000 validation images: 14.66 %\n",
            "Epoch [9/10], Step [71/71], Loss: 2.1951\n",
            "Accuracy of the network on the 5000 validation images: 15.32 %\n",
            "Epoch [10/10], Step [71/71], Loss: 2.2486\n",
            "Accuracy of the network on the 5000 validation images: 13.44 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the Adam optimizer with a learning rate of $0.005$ resulted in suboptimal performance, as reflected in a higher loss function and lower accuracy on the validation images compared to learning rate of $0.00005$."
      ],
      "metadata": {
        "id": "9h6ZCdvd7fI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total)) "
      ],
      "metadata": {
        "id": "8FtDeB9cGykq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1cbbf7-ec40-4cf4-8e92-0af14ca6c846"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 13.63 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Q3:**\n",
        "The network architecture so that it doesn't include Batch Normalization or Dropout layers.\n",
        "we will train using the Adam optimizer on the training data with a learning rate of $0.00005$, and the output of the section below will print the Loss of each Epoch and Accuracy of the network on the $5000$ validation images of each epoch."
      ],
      "metadata": {
        "id": "PoZmeGwREi2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            # nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            # nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            # nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
        "            # nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.fc = nn.Sequential(\n",
        "            # nn.Dropout(0.5),\n",
        "            nn.Linear(9216, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            # nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "5fE9qLKBCtyx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.00005\n",
        "\n",
        "\n",
        "model = AlexNet(num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n"
      ],
      "metadata": {
        "id": "9rXlCyyNCKru"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "total_step = len(train_loader)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, running_loss / len(train_loader)))\n",
        "            \n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "    \n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lWmlGrfDIC_",
        "outputId": "4862fffb-b227-4653-e489-d1e6a2d7c515"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [71/71], Loss: 1.8002\n",
            "Accuracy of the network on the 5000 validation images: 39.96 %\n",
            "Epoch [2/10], Step [71/71], Loss: 1.4762\n",
            "Accuracy of the network on the 5000 validation images: 48.74 %\n",
            "Epoch [3/10], Step [71/71], Loss: 1.2711\n",
            "Accuracy of the network on the 5000 validation images: 51.84 %\n",
            "Epoch [4/10], Step [71/71], Loss: 1.1043\n",
            "Accuracy of the network on the 5000 validation images: 54.6 %\n",
            "Epoch [5/10], Step [71/71], Loss: 0.9780\n",
            "Accuracy of the network on the 5000 validation images: 53.5 %\n",
            "Epoch [6/10], Step [71/71], Loss: 0.8312\n",
            "Accuracy of the network on the 5000 validation images: 57.66 %\n",
            "Epoch [7/10], Step [71/71], Loss: 0.6920\n",
            "Accuracy of the network on the 5000 validation images: 56.42 %\n",
            "Epoch [8/10], Step [71/71], Loss: 0.5758\n",
            "Accuracy of the network on the 5000 validation images: 62.44 %\n",
            "Epoch [9/10], Step [71/71], Loss: 0.4355\n",
            "Accuracy of the network on the 5000 validation images: 60.12 %\n",
            "Epoch [10/10], Step [71/71], Loss: 0.3141\n",
            "Accuracy of the network on the 5000 validation images: 60.62 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total)) "
      ],
      "metadata": {
        "id": "gkTLFAuMG2OE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d7691c-4f42-42b9-ab86-14457b1e209e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 61.86 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "it is seems like there is does'nt change the accelerate the learning process. "
      ],
      "metadata": {
        "id": "BXcDnXazF2tG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Bonus Section**"
      ],
      "metadata": {
        "id": "S9WcKXn0GZMb"
      }
    }
  ]
}